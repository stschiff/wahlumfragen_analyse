---
title: "R Notebook"
output: html_notebook
---

# 2013-2017 data

```{R include=FALSE}
library(magrittr)
library(ggplot2)

source('defs.R')
```

Let's load all polls from the 1st of October 2013 (shortly after the 2013 election) until the 21st of September 2017 (one day before the last election):

```{R loading}
dat <- import_polldat_all() %>% dplyr::filter(Release_Date > "2013-10-01" & Release_Date < "2017-09-24")
```

```{r}
# diff <- learn_diffusion(dat)
diff <- 0.00637722
fb_df <- dat %>% run_forward_backward(diff)
dplyr::rename(dat, Date = Release_Date) %>% plot_polldat_with_model(fb_df, date_col1 = "Date")
```


# How well did the polls do in predicting the election?


```{R plotting dists}
deviation <- projection_beta(fb_df, "2017-09-24") %>%
  dplyr::left_join(tibble::tibble(
    party = c("CDU_CSU", "SPD", "GRÃœNE", "FDP", "LINKE", "AFD"),
    results = c(33.0, 20.5, 8.9, 10.7, 9.2, 12.6)
  ), by="party") %>%
  dplyr::select(party, q025, q975, results) %>%
  dplyr::mutate(
    deviation = ifelse(results > q975 * 100, results - q975 * 100, ifelse(results > q025 * 100, 0, q025 * 100 - results))
  )
deviation
```

So deviations between 0.12 and 1.5 percent points between our prediction band and the true results. We can compute an average:

```{r}
mean(deviation$deviation)
```

so on average 0.7% off. Not too bad. But we can take that into account when simulating election results.
